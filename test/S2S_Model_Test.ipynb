{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from matplotlib import pyplot as plt\n",
    "from math import exp, sqrt, log\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from importlib import reload\n",
    "#reload(util_tools)\n",
    "import util_tools\n",
    "from util_tools.data_loader import data_processer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary parameters\n",
    "target_var = 'DUSMASS'\n",
    "file_path_g_06 = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20060516-20070515.nc'\n",
    "file_path_g_05 = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20050516-20060515.nc'\n",
    "file_path_m = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\MERRA2_aerosol_variables_over_MiddleEast_daily_20000516-20180515.nc'\n",
    "file_path_ele = r'C:\\Users\\96349\\Documents\\Downscale_data\\elevation\\elevation_data.npy'\n",
    "file_path_country = [r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\AFG_adm/AFG_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\ARE_adm/ARE_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\IRQ_adm/IRQ_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\KWT_adm/KWT_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\QAT_adm/QAT_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\SAU_adm/SAU_adm0.shp']\n",
    "n_lag = 4\n",
    "n_pred = 2\n",
    "task_dim = [5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util_tools.data_loader)\n",
    "import util_tools.data_loader as data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = data_loader.data_processer(0.2, 10)\n",
    "g_data, m_data, [G_lats, G_lons, M_lats, M_lons], ele_data = data_processor.load_data(target_var, file_path_g_05, file_path_g_06, file_path_m, file_path_ele, file_path_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = data_processor.unify_m_data(g_data, m_data, G_lats, G_lons, M_lats, M_lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_m_data = m_data[range(1826, 1826+730), :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high, X_low, X_ele, X_other, Y = data_processor.flatten(g_data[:10, :10, :10], match_m_data[:10, :10, :10], ele_data[:10, :10],\n",
    "                                                          [G_lats[:10], G_lons[:10]], list(range(10)), n_lag=n_lag, n_pred=n_pred, task_dim=task_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 2, 5, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 2, 5, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([Y, Y], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1]*3+[0]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.000000e+01, 3.600000e+01, 4.000000e+01, 4.000000e+01,\n",
       "        0.000000e+00, 4.000000e+01, 0.000000e+00, 0.000000e+00,\n",
       "        8.000000e+01, 3.500000e+01, 1.500000e+02, 0.000000e+00,\n",
       "        2.000000e+01, 8.000000e+01, 1.500000e+02, 2.400000e+02,\n",
       "        2.250000e+02, 1.120000e+02, 3.450000e+02, 8.100000e+02,\n",
       "        3.320000e+02, 4.800000e+02, 9.260000e+02, 8.600000e+02,\n",
       "        1.529000e+03, 1.397000e+03, 1.234000e+03, 1.062000e+03,\n",
       "        2.165000e+03, 2.520000e+03, 2.255000e+03, 2.725000e+03,\n",
       "        4.080000e+03, 3.994000e+03, 4.811000e+03, 6.892000e+03,\n",
       "        1.124900e+04, 9.082000e+03, 1.463400e+04, 1.554500e+04,\n",
       "        1.951800e+04, 3.051800e+04, 4.075500e+04, 5.405400e+04,\n",
       "        6.792400e+04, 1.020750e+05, 1.387730e+05, 1.995700e+05,\n",
       "        2.737010e+05, 3.523580e+05, 4.408580e+05, 5.515720e+05,\n",
       "        7.187690e+05, 8.903840e+05, 1.155296e+06, 1.422249e+06,\n",
       "        1.813775e+06, 2.325699e+06, 2.884360e+06, 3.546831e+06,\n",
       "        4.277757e+06, 5.139129e+06, 5.991417e+06, 6.867667e+06,\n",
       "        7.782329e+06, 8.603480e+06, 9.303668e+06, 9.631761e+06,\n",
       "        9.720269e+06, 9.616972e+06, 9.214252e+06, 8.617480e+06,\n",
       "        7.822092e+06, 7.045785e+06, 6.179805e+06, 5.306318e+06,\n",
       "        4.576117e+06, 3.934946e+06, 3.386858e+06, 2.900802e+06,\n",
       "        2.510439e+06, 2.147853e+06, 1.852785e+06, 1.618486e+06,\n",
       "        1.391693e+06, 1.157219e+06, 9.754340e+05, 7.527670e+05,\n",
       "        5.692160e+05, 4.229510e+05, 3.022630e+05, 2.078730e+05,\n",
       "        1.366860e+05, 8.422100e+04, 5.310200e+04, 2.959500e+04,\n",
       "        1.574700e+04, 8.019000e+03, 3.833000e+03, 3.900000e+02]),\n",
       " array([0.15023271, 0.15946033, 0.16868796, 0.17791559, 0.18714322,\n",
       "        0.19637085, 0.20559847, 0.2148261 , 0.22405373, 0.23328136,\n",
       "        0.24250898, 0.25173661, 0.26096424, 0.27019187, 0.2794195 ,\n",
       "        0.28864712, 0.29787475, 0.30710238, 0.31633001, 0.32555764,\n",
       "        0.33478526, 0.34401289, 0.35324052, 0.36246815, 0.37169577,\n",
       "        0.3809234 , 0.39015103, 0.39937866, 0.40860629, 0.41783391,\n",
       "        0.42706154, 0.43628917, 0.4455168 , 0.45474443, 0.46397205,\n",
       "        0.47319968, 0.48242731, 0.49165494, 0.50088256, 0.51011019,\n",
       "        0.51933782, 0.52856545, 0.53779308, 0.5470207 , 0.55624833,\n",
       "        0.56547596, 0.57470359, 0.58393122, 0.59315884, 0.60238647,\n",
       "        0.6116141 , 0.62084173, 0.63006935, 0.63929698, 0.64852461,\n",
       "        0.65775224, 0.66697987, 0.67620749, 0.68543512, 0.69466275,\n",
       "        0.70389038, 0.71311801, 0.72234563, 0.73157326, 0.74080089,\n",
       "        0.75002852, 0.75925614, 0.76848377, 0.7777114 , 0.78693903,\n",
       "        0.79616666, 0.80539428, 0.81462191, 0.82384954, 0.83307717,\n",
       "        0.8423048 , 0.85153242, 0.86076005, 0.86998768, 0.87921531,\n",
       "        0.88844293, 0.89767056, 0.90689819, 0.91612582, 0.92535345,\n",
       "        0.93458107, 0.9438087 , 0.95303633, 0.96226396, 0.97149159,\n",
       "        0.98071921, 0.98994684, 0.99917447, 1.0084021 , 1.01762972,\n",
       "        1.02685735, 1.03608498, 1.04531261, 1.05454024, 1.06376786,\n",
       "        1.07299549]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(m_data.reshape(np.prod(m_data.shape)), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.000000e+00, 5.000000e+00, 1.000000e+01, 1.800000e+01,\n",
       "        2.900000e+01, 4.800000e+01, 5.700000e+01, 6.500000e+01,\n",
       "        9.500000e+01, 1.750000e+02, 2.180000e+02, 1.990000e+02,\n",
       "        1.950000e+02, 2.370000e+02, 3.260000e+02, 4.030000e+02,\n",
       "        5.460000e+02, 6.880000e+02, 8.040000e+02, 4.460000e+02,\n",
       "        3.130000e+02, 2.820000e+02, 2.880000e+02, 3.160000e+02,\n",
       "        3.420000e+02, 3.010000e+02, 3.120000e+02, 3.180000e+02,\n",
       "        3.210000e+02, 3.280000e+02, 3.410000e+02, 3.220000e+02,\n",
       "        3.010000e+02, 2.890000e+02, 2.050000e+02, 1.860000e+02,\n",
       "        1.830000e+02, 2.420000e+02, 1.980000e+02, 2.350000e+02,\n",
       "        2.430000e+02, 2.760000e+02, 3.080000e+02, 3.380000e+02,\n",
       "        3.730000e+02, 3.680000e+02, 4.060000e+02, 3.990000e+02,\n",
       "        4.160000e+02, 4.560000e+02, 5.310000e+02, 5.880000e+02,\n",
       "        5.010000e+02, 4.430000e+02, 4.730000e+02, 4.400000e+02,\n",
       "        3.960000e+02, 4.420000e+02, 4.550000e+02, 4.850000e+02,\n",
       "        4.370000e+02, 4.680000e+02, 4.500000e+02, 5.030000e+02,\n",
       "        4.890000e+02, 5.360000e+02, 6.180000e+02, 7.210000e+02,\n",
       "        8.610000e+02, 9.650000e+02, 9.110000e+02, 1.226000e+03,\n",
       "        1.670000e+03, 2.380000e+03, 2.462000e+03, 2.845000e+03,\n",
       "        3.328000e+03, 3.776000e+03, 4.703000e+03, 4.071000e+03,\n",
       "        3.024000e+03, 4.077000e+03, 5.171000e+03, 5.987000e+03,\n",
       "        9.069000e+03, 6.663000e+03, 2.799300e+04, 1.927580e+05,\n",
       "        6.727320e+05, 1.622754e+06, 2.589532e+06, 3.113772e+06,\n",
       "        2.993426e+06, 2.448527e+06, 1.932987e+06, 1.428502e+06,\n",
       "        9.086630e+05, 4.521280e+05, 1.093100e+05, 7.508000e+03]),\n",
       " array([0.        , 0.01007503, 0.02015005, 0.03022508, 0.0403001 ,\n",
       "        0.05037513, 0.06045016, 0.07052518, 0.08060021, 0.09067524,\n",
       "        0.10075026, 0.11082529, 0.12090031, 0.13097534, 0.14105037,\n",
       "        0.15112539, 0.16120042, 0.17127545, 0.18135047, 0.1914255 ,\n",
       "        0.20150052, 0.21157555, 0.22165058, 0.2317256 , 0.24180063,\n",
       "        0.25187566, 0.26195068, 0.27202571, 0.28210073, 0.29217576,\n",
       "        0.30225079, 0.31232581, 0.32240084, 0.33247587, 0.34255089,\n",
       "        0.35262592, 0.36270094, 0.37277597, 0.382851  , 0.39292602,\n",
       "        0.40300105, 0.41307608, 0.4231511 , 0.43322613, 0.44330115,\n",
       "        0.45337618, 0.46345121, 0.47352623, 0.48360126, 0.49367628,\n",
       "        0.50375131, 0.51382634, 0.52390136, 0.53397639, 0.54405142,\n",
       "        0.55412644, 0.56420147, 0.57427649, 0.58435152, 0.59442655,\n",
       "        0.60450157, 0.6145766 , 0.62465163, 0.63472665, 0.64480168,\n",
       "        0.6548767 , 0.66495173, 0.67502676, 0.68510178, 0.69517681,\n",
       "        0.70525184, 0.71532686, 0.72540189, 0.73547691, 0.74555194,\n",
       "        0.75562697, 0.76570199, 0.77577702, 0.78585205, 0.79592707,\n",
       "        0.8060021 , 0.81607712, 0.82615215, 0.83622718, 0.8463022 ,\n",
       "        0.85637723, 0.86645225, 0.87652728, 0.88660231, 0.89667733,\n",
       "        0.90675236, 0.91682739, 0.92690241, 0.93697744, 0.94705246,\n",
       "        0.95712749, 0.96720252, 0.97727754, 0.98735257, 0.9974276 ,\n",
       "        1.00750262]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(g_data.reshape(np.prod(g_data.shape)), bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GAN model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnelu(input):\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "high_input = tf.keras.Input(shape=(n_lag, task_dim[0], task_dim[1], 1))\n",
    "x1 = tf.keras.layers.ConvLSTM2D(16, kernel_size=(3,3), return_sequences=True, activation=tf.keras.layers.LeakyReLU())(high_input)\n",
    "x1 = tf.keras.layers.ConvLSTM2D(16, kernel_size=(3,3), return_sequences=True, activation=tf.keras.layers.LeakyReLU())(x1)\n",
    "x1 = tf.keras.layers.ConvLSTM2D(16, kernel_size=(1,1), activation=tf.keras.layers.LeakyReLU())(x1)\n",
    "x1 = tf.keras.layers.Flatten()(x1)\n",
    "\n",
    "low_input = tf.keras.Input(shape=(n_lag, task_dim[0], task_dim[1], 1))\n",
    "x2 = tf.keras.layers.ConvLSTM2D(16, kernel_size=(3,3), activation=tf.keras.layers.LeakyReLU())(low_input)\n",
    "x2 = tf.keras.layers.Flatten()(x1)\n",
    "\n",
    "ele_input = tf.keras.Input(shape=(task_dim[0], task_dim[1], 1))\n",
    "x3 = tf.keras.layers.Conv2D(16, kernel_size=(3,3), activation=tf.keras.layers.LeakyReLU())(ele_input)\n",
    "x3 = tf.keras.layers.Flatten()(x3)\n",
    "\n",
    "other_input =  tf.keras.Input(shape=(3))\n",
    "x4 = tf.keras.layers.Dense(8, activation=tf.keras.layers.LeakyReLU())(other_input)\n",
    "\n",
    "x = tf.keras.layers.Concatenate(axis=1)([x1, x2, x3, x4])\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(30, activation=tf.keras.layers.LeakyReLU())(x)\n",
    "x = tf.keras.layers.Dense(n_pred*np.prod(task_dim), activation=nnelu)(x)\n",
    "x = tf.keras.layers.Reshape([n_pred, task_dim[0], task_dim[1]])(x)\n",
    "generator = tf.keras.Model([high_input, low_input, ele_input, other_input], x)\n",
    "generator.compile(optimizer='adam', loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 12s 16ms/step - loss: 0.1867\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1435\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1132\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0977\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0825\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0711\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0630\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0555\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0504\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0432\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0409\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0358\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0322\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0295\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0262\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0235\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0221\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0203\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0194\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0180\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0167\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0161\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0144\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0137\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0132\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0127\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0120\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0118\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0111\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0107\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0104\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0102\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0101\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0098\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0098\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0094\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0093\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0090\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0089\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0089\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0086\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0086\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0084\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0082\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0082\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0080\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0079\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0080\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0079\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0078\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0079\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0079\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0076\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0076\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0076\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0074\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0074\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0073\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0074\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0073\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0071\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0071\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0071\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0070\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0071\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0070\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0070\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0069\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0069\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0068\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0070\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0068\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0067\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0068\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0068\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0067\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0067\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0068\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0067\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0066\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0065\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0065\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0065\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0066\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0065\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0066\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0064\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0064\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0063\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0066\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0063\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0063\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0066\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0066\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0066\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0065\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0064\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0064\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0061\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263d4423508>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.fit([X_high[:-1], X_low[:-1], X_ele[:-1], X_other[:-1]], Y[:-1], epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 127 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000263E0072DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pred_Y = generator.predict([X_high[-1:], X_low[-1:], X_ele[-1:], X_other[-1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010288388300887755"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.square(pred_Y[-1] - Y[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008515162367835552, 0.6608753429840621)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util_tools.data_processing import rsquared\n",
    "rsquared(pred_Y[0, 0].reshape((25)), Y[0,0].reshape((25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input = tf.keras.Input(shape=(n_pred, task_dim[0], task_dim[1]))\n",
    "y1 = tf.keras.layers.Flatten()(pred_input)\n",
    "'''\n",
    "condition_input = tf.keras.Input(shape=(3))\n",
    "y2 = tf.keras.layers.Dense(8, activation='relu')(condition_input)\n",
    "y = tf.keras.layers.Concatenate(axis=1)([y1, y2])\n",
    "'''\n",
    "y = tf.keras.layers.Dense(8, activation=tf.keras.layers.LeakyReLU())(y1)\n",
    "y = tf.keras.layers.Dropout(0.8)(y)\n",
    "y = tf.keras.layers.Dense(1, activation='sigmoid')(y)\n",
    "discriminator = tf.keras.Model([pred_input], y)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util_tools.cGAN_model)\n",
    "from util_tools.cGAN_model import  Condition_GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, batch:1/6, real_loss=1.581, fake_loss=0.634, g_loss=0.720\n",
      "Epoch:1, batch:2/6, real_loss=2.333, fake_loss=0.666, g_loss=0.657\n",
      "Epoch:1, batch:3/6, real_loss=0.591, fake_loss=0.600, g_loss=0.677\n",
      "Epoch:1, batch:4/6, real_loss=1.211, fake_loss=0.720, g_loss=0.711\n",
      "Epoch:1, batch:5/6, real_loss=0.957, fake_loss=0.657, g_loss=0.642\n",
      "Epoch:1, batch:6/6, real_loss=1.126, fake_loss=0.806, g_loss=0.694\n",
      "Epoch:2, batch:1/6, real_loss=0.959, fake_loss=0.756, g_loss=0.705\n",
      "Epoch:2, batch:2/6, real_loss=2.761, fake_loss=0.704, g_loss=0.673\n",
      "Epoch:2, batch:3/6, real_loss=1.737, fake_loss=0.568, g_loss=0.654\n",
      "Epoch:2, batch:4/6, real_loss=1.243, fake_loss=0.695, g_loss=0.611\n",
      "Epoch:2, batch:5/6, real_loss=1.803, fake_loss=0.713, g_loss=0.666\n",
      "Epoch:2, batch:6/6, real_loss=1.845, fake_loss=0.598, g_loss=0.665\n",
      "Epoch:3, batch:1/6, real_loss=1.941, fake_loss=0.697, g_loss=0.711\n",
      "Epoch:3, batch:2/6, real_loss=0.579, fake_loss=0.704, g_loss=0.661\n",
      "Epoch:3, batch:3/6, real_loss=1.478, fake_loss=0.692, g_loss=0.692\n",
      "Epoch:3, batch:4/6, real_loss=1.497, fake_loss=0.742, g_loss=0.706\n",
      "Epoch:3, batch:5/6, real_loss=0.304, fake_loss=0.676, g_loss=0.650\n",
      "Epoch:3, batch:6/6, real_loss=0.372, fake_loss=0.513, g_loss=0.709\n",
      "Epoch:4, batch:1/6, real_loss=0.229, fake_loss=0.474, g_loss=0.690\n",
      "Epoch:4, batch:2/6, real_loss=0.492, fake_loss=0.572, g_loss=0.673\n",
      "Epoch:4, batch:3/6, real_loss=0.352, fake_loss=0.596, g_loss=0.689\n",
      "Epoch:4, batch:4/6, real_loss=0.033, fake_loss=0.696, g_loss=0.690\n",
      "Epoch:4, batch:5/6, real_loss=0.982, fake_loss=0.688, g_loss=0.679\n",
      "Epoch:4, batch:6/6, real_loss=0.556, fake_loss=0.694, g_loss=0.673\n",
      "Epoch:5, batch:1/6, real_loss=1.125, fake_loss=0.738, g_loss=0.676\n",
      "Epoch:5, batch:2/6, real_loss=0.346, fake_loss=0.657, g_loss=0.689\n",
      "Epoch:5, batch:3/6, real_loss=1.430, fake_loss=0.534, g_loss=0.683\n",
      "Epoch:5, batch:4/6, real_loss=0.538, fake_loss=0.629, g_loss=0.653\n",
      "Epoch:5, batch:5/6, real_loss=0.277, fake_loss=0.672, g_loss=0.688\n",
      "Epoch:5, batch:6/6, real_loss=0.287, fake_loss=0.725, g_loss=0.641\n",
      "Epoch:6, batch:1/6, real_loss=0.694, fake_loss=0.685, g_loss=0.671\n",
      "Epoch:6, batch:2/6, real_loss=0.264, fake_loss=0.699, g_loss=0.691\n",
      "Epoch:6, batch:3/6, real_loss=0.313, fake_loss=0.617, g_loss=0.670\n",
      "Epoch:6, batch:4/6, real_loss=0.223, fake_loss=0.723, g_loss=0.676\n",
      "Epoch:6, batch:5/6, real_loss=0.383, fake_loss=0.661, g_loss=0.653\n",
      "Epoch:6, batch:6/6, real_loss=0.169, fake_loss=0.709, g_loss=0.642\n",
      "Epoch:7, batch:1/6, real_loss=0.967, fake_loss=0.588, g_loss=0.652\n",
      "Epoch:7, batch:2/6, real_loss=0.430, fake_loss=0.602, g_loss=0.664\n",
      "Epoch:7, batch:3/6, real_loss=0.409, fake_loss=0.669, g_loss=0.631\n",
      "Epoch:7, batch:4/6, real_loss=0.347, fake_loss=0.702, g_loss=0.629\n",
      "Epoch:7, batch:5/6, real_loss=0.411, fake_loss=0.707, g_loss=0.637\n",
      "Epoch:7, batch:6/6, real_loss=0.011, fake_loss=0.516, g_loss=0.626\n",
      "Epoch:8, batch:1/6, real_loss=0.433, fake_loss=0.623, g_loss=0.608\n",
      "Epoch:8, batch:2/6, real_loss=0.375, fake_loss=0.699, g_loss=0.633\n",
      "Epoch:8, batch:3/6, real_loss=0.504, fake_loss=0.575, g_loss=0.624\n",
      "Epoch:8, batch:4/6, real_loss=0.794, fake_loss=0.568, g_loss=0.649\n",
      "Epoch:8, batch:5/6, real_loss=0.178, fake_loss=0.538, g_loss=0.626\n",
      "Epoch:8, batch:6/6, real_loss=0.053, fake_loss=0.659, g_loss=0.620\n",
      "Epoch:9, batch:1/6, real_loss=0.976, fake_loss=0.658, g_loss=0.586\n",
      "Epoch:9, batch:2/6, real_loss=0.356, fake_loss=0.673, g_loss=0.637\n",
      "Epoch:9, batch:3/6, real_loss=0.216, fake_loss=0.525, g_loss=0.545\n",
      "Epoch:9, batch:4/6, real_loss=0.897, fake_loss=0.627, g_loss=0.562\n",
      "Epoch:9, batch:5/6, real_loss=0.429, fake_loss=0.643, g_loss=0.618\n",
      "Epoch:9, batch:6/6, real_loss=0.420, fake_loss=0.500, g_loss=0.597\n",
      "Epoch:10, batch:1/6, real_loss=0.352, fake_loss=0.361, g_loss=0.557\n",
      "Epoch:10, batch:2/6, real_loss=0.743, fake_loss=0.515, g_loss=0.629\n",
      "Epoch:10, batch:3/6, real_loss=0.356, fake_loss=0.480, g_loss=0.599\n",
      "Epoch:10, batch:4/6, real_loss=0.583, fake_loss=0.581, g_loss=0.556\n",
      "Epoch:10, batch:5/6, real_loss=0.372, fake_loss=0.595, g_loss=0.575\n",
      "Epoch:10, batch:6/6, real_loss=0.422, fake_loss=0.497, g_loss=0.537\n",
      "Epoch:11, batch:1/6, real_loss=0.751, fake_loss=0.580, g_loss=0.534\n",
      "Epoch:11, batch:2/6, real_loss=0.478, fake_loss=0.690, g_loss=0.490\n",
      "Epoch:11, batch:3/6, real_loss=0.367, fake_loss=0.416, g_loss=0.511\n",
      "Epoch:11, batch:4/6, real_loss=0.622, fake_loss=0.509, g_loss=0.487\n",
      "Epoch:11, batch:5/6, real_loss=0.251, fake_loss=0.528, g_loss=0.521\n",
      "Epoch:11, batch:6/6, real_loss=0.252, fake_loss=0.214, g_loss=0.541\n",
      "Epoch:12, batch:1/6, real_loss=0.042, fake_loss=0.241, g_loss=0.521\n",
      "Epoch:12, batch:2/6, real_loss=0.076, fake_loss=0.505, g_loss=0.510\n",
      "Epoch:12, batch:3/6, real_loss=0.433, fake_loss=0.725, g_loss=0.421\n",
      "Epoch:12, batch:4/6, real_loss=0.184, fake_loss=0.225, g_loss=0.413\n",
      "Epoch:12, batch:5/6, real_loss=0.899, fake_loss=0.368, g_loss=0.484\n",
      "Epoch:12, batch:6/6, real_loss=0.299, fake_loss=0.689, g_loss=0.472\n",
      "Epoch:13, batch:1/6, real_loss=0.281, fake_loss=0.185, g_loss=0.336\n",
      "Epoch:13, batch:2/6, real_loss=0.830, fake_loss=0.280, g_loss=0.497\n",
      "Epoch:13, batch:3/6, real_loss=0.255, fake_loss=0.514, g_loss=0.493\n",
      "Epoch:13, batch:4/6, real_loss=0.177, fake_loss=0.156, g_loss=0.420\n",
      "Epoch:13, batch:5/6, real_loss=0.453, fake_loss=0.384, g_loss=0.461\n",
      "Epoch:13, batch:6/6, real_loss=0.212, fake_loss=0.005, g_loss=0.366\n",
      "Epoch:14, batch:1/6, real_loss=0.394, fake_loss=0.036, g_loss=0.477\n",
      "Epoch:14, batch:2/6, real_loss=0.502, fake_loss=0.400, g_loss=0.405\n",
      "Epoch:14, batch:3/6, real_loss=0.110, fake_loss=0.674, g_loss=0.533\n",
      "Epoch:14, batch:4/6, real_loss=0.002, fake_loss=0.507, g_loss=0.363\n",
      "Epoch:14, batch:5/6, real_loss=0.215, fake_loss=0.403, g_loss=0.400\n",
      "Epoch:14, batch:6/6, real_loss=0.357, fake_loss=0.183, g_loss=0.391\n",
      "Epoch:15, batch:1/6, real_loss=0.142, fake_loss=0.607, g_loss=0.345\n",
      "Epoch:15, batch:2/6, real_loss=0.109, fake_loss=0.368, g_loss=0.314\n",
      "Epoch:15, batch:3/6, real_loss=0.467, fake_loss=0.612, g_loss=0.349\n",
      "Epoch:15, batch:4/6, real_loss=0.349, fake_loss=0.346, g_loss=0.374\n",
      "Epoch:15, batch:5/6, real_loss=0.349, fake_loss=0.637, g_loss=0.409\n",
      "Epoch:15, batch:6/6, real_loss=0.684, fake_loss=0.325, g_loss=0.384\n",
      "Epoch:16, batch:1/6, real_loss=0.369, fake_loss=0.307, g_loss=0.316\n",
      "Epoch:16, batch:2/6, real_loss=0.349, fake_loss=0.184, g_loss=0.281\n",
      "Epoch:16, batch:3/6, real_loss=0.737, fake_loss=0.688, g_loss=0.244\n",
      "Epoch:16, batch:4/6, real_loss=0.359, fake_loss=0.213, g_loss=0.283\n",
      "Epoch:16, batch:5/6, real_loss=0.370, fake_loss=0.003, g_loss=0.328\n",
      "Epoch:16, batch:6/6, real_loss=0.075, fake_loss=0.482, g_loss=0.262\n",
      "Epoch:17, batch:1/6, real_loss=0.532, fake_loss=0.349, g_loss=0.365\n",
      "Epoch:17, batch:2/6, real_loss=0.349, fake_loss=0.394, g_loss=0.334\n",
      "Epoch:17, batch:3/6, real_loss=0.351, fake_loss=0.015, g_loss=0.257\n",
      "Epoch:17, batch:4/6, real_loss=0.531, fake_loss=0.154, g_loss=0.310\n",
      "Epoch:17, batch:5/6, real_loss=0.237, fake_loss=0.346, g_loss=0.355\n",
      "Epoch:17, batch:6/6, real_loss=0.355, fake_loss=0.344, g_loss=0.265\n",
      "Epoch:18, batch:1/6, real_loss=0.153, fake_loss=0.309, g_loss=0.156\n",
      "Epoch:18, batch:2/6, real_loss=0.012, fake_loss=0.525, g_loss=0.293\n",
      "Epoch:18, batch:3/6, real_loss=0.698, fake_loss=0.371, g_loss=0.428\n",
      "Epoch:18, batch:4/6, real_loss=0.567, fake_loss=0.237, g_loss=0.310\n",
      "Epoch:18, batch:5/6, real_loss=0.305, fake_loss=0.419, g_loss=0.217\n",
      "Epoch:18, batch:6/6, real_loss=0.274, fake_loss=0.025, g_loss=0.128\n",
      "Epoch:19, batch:1/6, real_loss=0.455, fake_loss=0.023, g_loss=0.206\n",
      "Epoch:19, batch:2/6, real_loss=0.042, fake_loss=0.396, g_loss=0.213\n",
      "Epoch:19, batch:3/6, real_loss=0.398, fake_loss=0.217, g_loss=0.348\n",
      "Epoch:19, batch:4/6, real_loss=0.362, fake_loss=0.275, g_loss=0.220\n",
      "Epoch:19, batch:5/6, real_loss=0.134, fake_loss=0.075, g_loss=0.220\n",
      "Epoch:19, batch:6/6, real_loss=0.302, fake_loss=0.689, g_loss=0.117\n",
      "Epoch:20, batch:1/6, real_loss=0.008, fake_loss=0.049, g_loss=0.135\n",
      "Epoch:20, batch:2/6, real_loss=0.687, fake_loss=0.000, g_loss=0.366\n",
      "Epoch:20, batch:3/6, real_loss=0.068, fake_loss=0.292, g_loss=0.292\n",
      "Epoch:20, batch:4/6, real_loss=0.360, fake_loss=0.061, g_loss=0.320\n",
      "Epoch:20, batch:5/6, real_loss=0.141, fake_loss=0.026, g_loss=0.246\n",
      "Epoch:20, batch:6/6, real_loss=0.067, fake_loss=0.345, g_loss=0.183\n"
     ]
    }
   ],
   "source": [
    "cGAN = Condition_GAN(generator, discriminator)\n",
    "cGAN.fit(20, 30, [X_high, X_low, X_ele, X_other], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2.098398  , 6.8347626 , 0.        , 0.        , 7.251035  ],\n",
       "         [0.        , 0.        , 1.2306697 , 5.5695524 , 2.0366979 ],\n",
       "         [1.7452251 , 0.        , 0.39746153, 0.        , 0.        ],\n",
       "         [0.        , 5.977245  , 2.5792408 , 2.9709916 , 0.        ],\n",
       "         [0.        , 0.        , 4.167796  , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "         [2.2004614 , 0.        , 0.        , 1.41692   , 1.7046547 ],\n",
       "         [0.        , 0.        , 1.6035516 , 0.        , 0.        ],\n",
       "         [0.18189768, 0.        , 1.1744812 , 3.1120594 , 0.        ],\n",
       "         [1.6918491 , 4.8302684 , 0.        , 0.        , 0.4495553 ]]],\n",
       "\n",
       "\n",
       "       [[[2.083576  , 6.7952433 , 0.        , 0.        , 7.212909  ],\n",
       "         [0.        , 0.        , 1.2202346 , 5.539638  , 2.0282161 ],\n",
       "         [1.7340379 , 0.        , 0.39515197, 0.        , 0.        ],\n",
       "         [0.        , 5.9439816 , 2.565229  , 2.9511387 , 0.        ],\n",
       "         [0.        , 0.        , 4.142496  , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "         [2.1892316 , 0.        , 0.        , 1.4069293 , 1.6942225 ],\n",
       "         [0.        , 0.        , 1.5956421 , 0.        , 0.        ],\n",
       "         [0.1885864 , 0.        , 1.1678602 , 3.0979276 , 0.        ],\n",
       "         [1.6813098 , 4.8020935 , 0.        , 0.        , 0.4443377 ]]],\n",
       "\n",
       "\n",
       "       [[[0.8089616 , 3.0795171 , 0.        , 0.        , 3.4583862 ],\n",
       "         [0.06259464, 0.        , 0.35334113, 2.58152   , 1.0567181 ],\n",
       "         [0.70053446, 0.        , 0.26534507, 0.        , 0.        ],\n",
       "         [0.        , 2.7733557 , 1.2836013 , 1.1975206 , 0.        ],\n",
       "         [0.        , 0.        , 1.8566285 , 0.        , 0.04026077]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "         [1.0756506 , 0.        , 0.        , 0.5250576 , 0.77686715],\n",
       "         [0.        , 0.        , 0.7886547 , 0.        , 0.        ],\n",
       "         [0.42544606, 0.        , 0.6030904 , 1.5236611 , 0.        ],\n",
       "         [0.77190316, 2.2498481 , 0.        , 0.        , 0.09696436]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.predict([X_high[:3], X_low[:3], X_ele[:3], X_other[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [X_high, X_low, X_ele, X_other]\n",
    "j =0\n",
    "batch_size=2\n",
    "batch_X = [d[j*batch_size:(j+1)*batch_size] for d in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 5, 5, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((batch_size, 1), dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Downscale_env",
   "language": "python",
   "name": "downscale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
