{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from matplotlib import pyplot as plt\n",
    "from math import exp, sqrt, log\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from importlib import reload\n",
    "#reload(util_tools)\n",
    "import util_tools\n",
    "from util_tools.data_loader import data_processer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary parameters\n",
    "target_var = 'DUEXTTAU'\n",
    "file_path_g_06 = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20060516-20070515.nc'\n",
    "file_path_g_05 = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20050516-20060515.nc'\n",
    "file_path_m = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\MERRA2_aerosol_variables_over_MiddleEast_daily_20000516-20180515.nc'\n",
    "file_path_ele = r'C:\\Users\\96349\\Documents\\Downscale_data\\elevation\\elevation_data.npy'\n",
    "file_path_country = [r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\AFG_adm/AFG_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\ARE_adm/ARE_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\IRQ_adm/IRQ_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\KWT_adm/KWT_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\QAT_adm/QAT_adm0.shp',\n",
    "                     r'C:\\Users\\96349\\Documents\\Downscale_data\\Country_shape\\SAU_adm/SAU_adm0.shp']\n",
    "n_lag = 20\n",
    "n_pred = 1\n",
    "task_dim = [5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(single_image_data, title, lats, lons, save_plt=False):\n",
    "    '''\n",
    "    if is_merra:\n",
    "        lons = MERRA_data.variables['lon'][:]\n",
    "        lats = MERRA_data.variables['lat'][:]\n",
    "    else:\n",
    "        lons = G5NR_data.variables['lon'][:]\n",
    "        lats = G5NR_data.variables['lat'][:]\n",
    "    '''\n",
    "    m = Basemap(projection='merc',llcrnrlon=25.,llcrnrlat=10.,urcrnrlon=75.,urcrnrlat=45. , resolution='h', epsg = 4326)\n",
    "    m.drawcoastlines()\n",
    "    m.drawstates()\n",
    "    m.drawcountries()\n",
    "    parallels = np.arange(10,43,5.) # make latitude lines ever 5 degrees from 30N-50N\n",
    "    meridians = np.arange(25,75,5.) # make longitude lines every 5 degrees from 95W to 70W\n",
    "    m.drawparallels(parallels,labels=[1,0,0,0],fontsize=10)\n",
    "    m.drawmeridians(meridians,labels=[0,0,0,1],fontsize=10)\n",
    "    #m.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)\n",
    "    m.shadedrelief(scale=0.5)\n",
    "    m.pcolormesh(lons, lats, single_image_data, latlon=True)\n",
    "    plt.clim(0, single_image_data.max())\n",
    "    m.drawcoastlines(color='lightgray')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if save_plt:\n",
    "        plt.savefig(title+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(util_tools.data_loader)\n",
    "import util_tools.data_loader as data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = data_loader.data_processer()\n",
    "g_data, m_data, [G_lats, G_lons, M_lats, M_lons], ele_data = data_processor.load_data(target_var, file_path_g_05, file_path_g_06, file_path_m, file_path_ele, file_path_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = data_processor.unify_m_data(g_data[:10], m_data, G_lats, G_lons, M_lats, M_lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_m_data = m_data[range(1826, 1826+730), :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 360, 647)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high, X_low, X_ele, X_other, Y = data_processor.flatten(g_data[:50, :30, :30], match_m_data[:50, :30, :30], ele_data[:30, :30],\n",
    "                                                          [G_lats[:30], G_lons[:30]], list(range(50)), n_lag=n_lag, n_pred=n_pred, task_dim=task_dim, is_perm=True, \n",
    "                                                          return_Y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GAN model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnelu(input):\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def mapping_to_target_range( x, target_min=0, target_max=1 ) :\n",
    "    x02 = tf.keras.backend.tanh(x) + 1 # x in range(0,2)\n",
    "    scale = ( target_max-target_min )/2.\n",
    "    return  x02 * scale + target_min\n",
    "\n",
    "\n",
    "high_input = tf.keras.Input(shape=(n_lag, task_dim[0], task_dim[1], 1))\n",
    "x1 = tf.keras.layers.ConvLSTM2D(16, kernel_size=(3,3), return_sequences=True, activation=tf.keras.layers.LeakyReLU())(high_input)\n",
    "#x1 = tf.keras.layers.ConvLSTM2D(16, kernel_size=(3,3), activation=tf.keras.layers.LeakyReLU())(x1)\n",
    "x1 = tf.keras.layers.Flatten()(x1)\n",
    "\n",
    "low_input = tf.keras.Input(shape=(n_lag, task_dim[0], task_dim[1], 1))\n",
    "x2 = tf.keras.layers.ConvLSTM2D(16, kernel_size=(3,3), return_sequences=True, activation=tf.keras.layers.LeakyReLU())(low_input)\n",
    "x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "ele_input = tf.keras.Input(shape=(task_dim[0], task_dim[1], 1))\n",
    "x3 = tf.keras.layers.Conv2D(16, kernel_size=(3,3), activation=tf.keras.layers.LeakyReLU())(ele_input)\n",
    "x3 = tf.keras.layers.Flatten()(x3)\n",
    "\n",
    "other_input =  tf.keras.Input(shape=(3))\n",
    "x4 = tf.keras.layers.Dense(8, activation=tf.keras.layers.LeakyReLU())(other_input)\n",
    "\n",
    "x = tf.keras.layers.Concatenate(axis=1)([x1, x2, x3, x4])\n",
    "#x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(30, kernel_initializer=\"he_normal\", use_bias=True, activation=tf.keras.layers.LeakyReLU())(x)\n",
    "x = tf.keras.layers.Dense(30, kernel_initializer=\"he_normal\", use_bias=True, activation=tf.keras.layers.LeakyReLU())(x)\n",
    "x = tf.keras.layers.Dense(30, kernel_initializer=\"he_normal\", use_bias=True, activation=tf.keras.layers.LeakyReLU())(x)\n",
    "x = tf.keras.layers.Dense(30, kernel_initializer=\"he_normal\", use_bias=True, activation=tf.keras.layers.LeakyReLU())(x)\n",
    "x = tf.keras.layers.Dense(30, kernel_initializer=\"he_normal\", use_bias=True, activation=tf.keras.layers.LeakyReLU())(x)\n",
    "x = tf.keras.layers.Dense(30, kernel_initializer=\"he_normal\", use_bias=True, activation=tf.keras.layers.LeakyReLU())(x)\n",
    "x = tf.keras.layers.Dense(n_pred*np.prod(task_dim), activation=nnelu)(x)\n",
    "x = tf.keras.layers.Reshape([n_pred, task_dim[0], task_dim[1]])(x)\n",
    "generator = tf.keras.Model([high_input, low_input, ele_input, other_input], x)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "generator.compile(optimizer=opt, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475/476 [============================>.] - ETA: 0s - loss: 0.0074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_2_layer_call_fn, leaky_re_lu_2_layer_call_and_return_conditional_losses, leaky_re_lu_3_layer_call_fn, leaky_re_lu_3_layer_call_and_return_conditional_losses, leaky_re_lu_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "476/476 [==============================] - 61s 110ms/step - loss: 0.0074 - val_loss: 0.0029 - lr: 0.0050\n"
     ]
    }
   ],
   "source": [
    "# define callbacks\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, factor=0.1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "best_save = tf.keras.callbacks.ModelCheckpoint('s2s_model', save_best_only=True, monitor='val_loss', mode='min')\n",
    "callbacks = [lr_scheduler, early_stopping, best_save]\n",
    "\n",
    "history = generator.fit([X_high[:-3], X_low[:-3], X_ele[:-3], X_other[:-3]], Y[:-3], epochs=1, callbacks=callbacks, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00288"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(history.history['val_loss'][0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.96585596, 0.96535116, 0.        , 0.9653614 ],\n",
       "         [0.965236  , 0.96597326, 0.9651004 , 0.        , 0.96587306],\n",
       "         [0.96600735, 0.9657643 , 0.9659777 , 0.9651386 , 0.9654685 ],\n",
       "         [0.966095  , 0.96596116, 0.        , 0.96616995, 0.9652539 ],\n",
       "         [0.9658393 , 0.9666162 , 0.        , 0.96587276, 0.9654851 ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.9661002 , 0.96582234, 0.        , 0.9656026 ],\n",
       "         [0.9651752 , 0.966246  , 0.9657142 , 0.        , 0.9659857 ],\n",
       "         [0.965397  , 0.9660406 , 0.9659572 , 0.9658715 , 0.96645546],\n",
       "         [0.9660278 , 0.9664916 , 0.        , 0.96617365, 0.96510905],\n",
       "         [0.96557724, 0.9660495 , 0.        , 0.9666382 , 0.96577233]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.predict([X_high[-2:], X_low[-2:], X_ele[-2:], X_other[-2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.96209797, 0.9621877 , 0.96193371, 0.96189912, 0.96229232],\n",
       "         [0.96203399, 0.96214366, 0.96209948, 0.9618981 , 0.96197329],\n",
       "         [0.96180667, 0.96200721, 0.96211405, 0.96204762, 0.96190014],\n",
       "         [0.96150141, 0.96180359, 0.96189352, 0.96187211, 0.9616579 ],\n",
       "         [0.96111839, 0.96135704, 0.96149043, 0.96148572, 0.96143228]]],\n",
       "\n",
       "\n",
       "       [[[0.96630322, 0.96626718, 0.96622566, 0.96619059, 0.96614191],\n",
       "         [0.96634224, 0.96628981, 0.96623644, 0.96618365, 0.96611053],\n",
       "         [0.96633115, 0.96626986, 0.96620216, 0.96613494, 0.96606159],\n",
       "         [0.96629403, 0.96621372, 0.96615042, 0.96611402, 0.96609423],\n",
       "         [0.96622451, 0.96617284, 0.96615003, 0.96614539, 0.96615042]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_model = tf.keras.models.load_model('s2s_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).to_csv('history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = g2_model.predict([X_high[-1:], X_low[-1:], X_ele[-1:], X_other[-1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9427106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010288388300887755"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.square(pred_Y[-1] - Y[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008515162367835552, 0.6608753429840621)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util_tools.data_processing import rsquared\n",
    "rsquared(pred_Y[0, 0].reshape((25)), Y[0,0].reshape((25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input = tf.keras.Input(shape=(n_pred, task_dim[0], task_dim[1]))\n",
    "y1 = tf.keras.layers.Flatten()(pred_input)\n",
    "'''\n",
    "condition_input = tf.keras.Input(shape=(3))\n",
    "y2 = tf.keras.layers.Dense(8, activation='relu')(condition_input)\n",
    "y = tf.keras.layers.Concatenate(axis=1)([y1, y2])\n",
    "'''\n",
    "y = tf.keras.layers.Dense(8, activation=tf.keras.layers.LeakyReLU())(y1)\n",
    "y = tf.keras.layers.Dropout(0.8)(y)\n",
    "y = tf.keras.layers.Dense(1, activation='sigmoid')(y)\n",
    "discriminator = tf.keras.Model([pred_input], y)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(util_tools.cGAN_model)\n",
    "from util_tools.cGAN_model import  Condition_GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish discriminator training\n",
      "Epoch:1, batch:1/236, real_loss=1.107, fake_loss=0.390, g_loss=0.633\n",
      "finish discriminator training\n",
      "Epoch:1, batch:2/236, real_loss=1.259, fake_loss=0.380, g_loss=0.495\n",
      "finish discriminator training\n",
      "Epoch:1, batch:3/236, real_loss=1.342, fake_loss=0.151, g_loss=0.562\n",
      "finish discriminator training\n",
      "Epoch:1, batch:4/236, real_loss=2.989, fake_loss=0.583, g_loss=0.659\n",
      "finish discriminator training\n",
      "Epoch:1, batch:5/236, real_loss=1.352, fake_loss=0.526, g_loss=0.718\n",
      "finish discriminator training\n",
      "Epoch:1, batch:6/236, real_loss=1.291, fake_loss=1.061, g_loss=0.651\n",
      "finish discriminator training\n",
      "Epoch:1, batch:7/236, real_loss=2.735, fake_loss=1.187, g_loss=0.541\n",
      "finish discriminator training\n",
      "Epoch:1, batch:8/236, real_loss=1.387, fake_loss=0.224, g_loss=0.598\n",
      "finish discriminator training\n",
      "Epoch:1, batch:9/236, real_loss=1.317, fake_loss=0.172, g_loss=0.571\n",
      "finish discriminator training\n",
      "Epoch:1, batch:10/236, real_loss=1.387, fake_loss=0.655, g_loss=0.679\n",
      "finish discriminator training\n",
      "Epoch:1, batch:11/236, real_loss=1.838, fake_loss=0.954, g_loss=0.618\n",
      "finish discriminator training\n",
      "Epoch:1, batch:12/236, real_loss=1.514, fake_loss=0.453, g_loss=0.664\n",
      "finish discriminator training\n",
      "Epoch:1, batch:13/236, real_loss=1.546, fake_loss=0.513, g_loss=0.651\n",
      "finish discriminator training\n",
      "Epoch:1, batch:14/236, real_loss=1.238, fake_loss=0.326, g_loss=0.649\n",
      "finish discriminator training\n",
      "Epoch:1, batch:15/236, real_loss=0.752, fake_loss=1.392, g_loss=0.624\n",
      "finish discriminator training\n",
      "Epoch:1, batch:16/236, real_loss=0.860, fake_loss=0.429, g_loss=0.553\n",
      "finish discriminator training\n",
      "Epoch:1, batch:17/236, real_loss=0.693, fake_loss=0.547, g_loss=0.594\n",
      "finish discriminator training\n",
      "Epoch:1, batch:18/236, real_loss=0.791, fake_loss=0.382, g_loss=0.719\n",
      "finish discriminator training\n",
      "Epoch:1, batch:19/236, real_loss=2.713, fake_loss=0.706, g_loss=0.657\n",
      "finish discriminator training\n",
      "Epoch:1, batch:20/236, real_loss=0.957, fake_loss=0.721, g_loss=0.621\n",
      "finish discriminator training\n",
      "Epoch:1, batch:21/236, real_loss=1.097, fake_loss=0.646, g_loss=0.620\n",
      "finish discriminator training\n",
      "Epoch:1, batch:22/236, real_loss=1.472, fake_loss=0.439, g_loss=0.661\n",
      "finish discriminator training\n",
      "Epoch:1, batch:23/236, real_loss=0.998, fake_loss=0.591, g_loss=0.600\n",
      "finish discriminator training\n",
      "Epoch:1, batch:24/236, real_loss=1.009, fake_loss=0.729, g_loss=0.682\n",
      "finish discriminator training\n",
      "Epoch:1, batch:25/236, real_loss=1.068, fake_loss=0.531, g_loss=0.708\n",
      "finish discriminator training\n",
      "Epoch:1, batch:26/236, real_loss=1.751, fake_loss=0.788, g_loss=0.654\n",
      "finish discriminator training\n",
      "Epoch:1, batch:27/236, real_loss=1.202, fake_loss=0.522, g_loss=0.659\n",
      "finish discriminator training\n",
      "Epoch:1, batch:28/236, real_loss=1.794, fake_loss=0.631, g_loss=0.659\n",
      "finish discriminator training\n",
      "Epoch:1, batch:29/236, real_loss=1.089, fake_loss=0.845, g_loss=0.738\n",
      "finish discriminator training\n",
      "Epoch:1, batch:30/236, real_loss=1.364, fake_loss=0.508, g_loss=0.789\n",
      "finish discriminator training\n",
      "Epoch:1, batch:31/236, real_loss=1.237, fake_loss=0.333, g_loss=0.662\n",
      "finish discriminator training\n",
      "Epoch:1, batch:32/236, real_loss=0.826, fake_loss=0.434, g_loss=0.633\n",
      "finish discriminator training\n",
      "Epoch:1, batch:33/236, real_loss=0.864, fake_loss=0.505, g_loss=0.716\n",
      "finish discriminator training\n",
      "Epoch:1, batch:34/236, real_loss=0.759, fake_loss=0.635, g_loss=0.692\n",
      "finish discriminator training\n",
      "Epoch:1, batch:35/236, real_loss=0.765, fake_loss=0.460, g_loss=0.716\n",
      "finish discriminator training\n",
      "Epoch:1, batch:36/236, real_loss=1.158, fake_loss=0.653, g_loss=0.679\n",
      "finish discriminator training\n",
      "Epoch:1, batch:37/236, real_loss=1.050, fake_loss=0.775, g_loss=0.737\n",
      "finish discriminator training\n",
      "Epoch:1, batch:38/236, real_loss=0.842, fake_loss=0.590, g_loss=0.792\n",
      "finish discriminator training\n",
      "Epoch:1, batch:39/236, real_loss=1.377, fake_loss=1.086, g_loss=0.729\n",
      "finish discriminator training\n",
      "Epoch:1, batch:40/236, real_loss=0.686, fake_loss=0.922, g_loss=0.719\n",
      "finish discriminator training\n",
      "Epoch:1, batch:41/236, real_loss=0.860, fake_loss=0.657, g_loss=0.709\n",
      "finish discriminator training\n",
      "Epoch:1, batch:42/236, real_loss=0.479, fake_loss=0.879, g_loss=0.815\n",
      "finish discriminator training\n",
      "Epoch:1, batch:43/236, real_loss=0.667, fake_loss=0.820, g_loss=0.724\n",
      "finish discriminator training\n",
      "Epoch:1, batch:44/236, real_loss=0.664, fake_loss=0.709, g_loss=0.721\n",
      "finish discriminator training\n",
      "Epoch:1, batch:45/236, real_loss=1.133, fake_loss=0.813, g_loss=0.759\n",
      "finish discriminator training\n",
      "Epoch:1, batch:46/236, real_loss=0.759, fake_loss=0.802, g_loss=0.795\n",
      "finish discriminator training\n",
      "Epoch:1, batch:47/236, real_loss=0.819, fake_loss=0.794, g_loss=0.700\n",
      "finish discriminator training\n",
      "Epoch:1, batch:48/236, real_loss=0.959, fake_loss=0.639, g_loss=0.753\n",
      "finish discriminator training\n",
      "Epoch:1, batch:49/236, real_loss=1.067, fake_loss=0.489, g_loss=0.693\n",
      "finish discriminator training\n",
      "Epoch:1, batch:50/236, real_loss=0.752, fake_loss=0.634, g_loss=0.681\n",
      "finish discriminator training\n",
      "Epoch:1, batch:51/236, real_loss=0.805, fake_loss=0.536, g_loss=0.770\n",
      "finish discriminator training\n",
      "Epoch:1, batch:52/236, real_loss=0.763, fake_loss=0.527, g_loss=0.760\n",
      "finish discriminator training\n",
      "Epoch:1, batch:53/236, real_loss=0.703, fake_loss=0.463, g_loss=0.757\n",
      "finish discriminator training\n",
      "Epoch:1, batch:54/236, real_loss=0.743, fake_loss=0.721, g_loss=0.716\n",
      "finish discriminator training\n",
      "Epoch:1, batch:55/236, real_loss=0.897, fake_loss=0.826, g_loss=0.752\n",
      "finish discriminator training\n",
      "Epoch:1, batch:56/236, real_loss=1.000, fake_loss=0.546, g_loss=0.759\n",
      "finish discriminator training\n",
      "Epoch:1, batch:57/236, real_loss=0.933, fake_loss=1.170, g_loss=0.747\n",
      "finish discriminator training\n",
      "Epoch:1, batch:58/236, real_loss=0.971, fake_loss=0.840, g_loss=0.753\n",
      "finish discriminator training\n",
      "Epoch:1, batch:59/236, real_loss=0.991, fake_loss=1.072, g_loss=0.731\n",
      "finish discriminator training\n",
      "Epoch:1, batch:60/236, real_loss=0.635, fake_loss=0.566, g_loss=0.722\n",
      "finish discriminator training\n",
      "Epoch:1, batch:61/236, real_loss=1.260, fake_loss=0.562, g_loss=0.692\n",
      "finish discriminator training\n",
      "Epoch:1, batch:62/236, real_loss=0.955, fake_loss=0.793, g_loss=0.775\n",
      "finish discriminator training\n",
      "Epoch:1, batch:63/236, real_loss=0.735, fake_loss=0.631, g_loss=0.648\n",
      "finish discriminator training\n",
      "Epoch:1, batch:64/236, real_loss=0.965, fake_loss=0.592, g_loss=0.748\n",
      "finish discriminator training\n",
      "Epoch:1, batch:65/236, real_loss=0.897, fake_loss=1.013, g_loss=0.736\n",
      "finish discriminator training\n",
      "Epoch:1, batch:66/236, real_loss=0.693, fake_loss=0.975, g_loss=0.652\n",
      "finish discriminator training\n",
      "Epoch:1, batch:67/236, real_loss=0.588, fake_loss=0.804, g_loss=0.713\n",
      "finish discriminator training\n",
      "Epoch:1, batch:68/236, real_loss=0.861, fake_loss=0.742, g_loss=0.762\n",
      "finish discriminator training\n",
      "Epoch:1, batch:69/236, real_loss=0.638, fake_loss=0.689, g_loss=0.752\n",
      "finish discriminator training\n",
      "Epoch:1, batch:70/236, real_loss=0.679, fake_loss=1.019, g_loss=0.743\n",
      "finish discriminator training\n",
      "Epoch:1, batch:71/236, real_loss=0.770, fake_loss=0.798, g_loss=0.729\n",
      "finish discriminator training\n",
      "Epoch:1, batch:72/236, real_loss=0.520, fake_loss=0.510, g_loss=0.715\n",
      "finish discriminator training\n",
      "Epoch:1, batch:73/236, real_loss=0.797, fake_loss=0.849, g_loss=0.720\n",
      "finish discriminator training\n",
      "Epoch:1, batch:74/236, real_loss=1.056, fake_loss=0.714, g_loss=0.773\n",
      "finish discriminator training\n",
      "Epoch:1, batch:75/236, real_loss=0.698, fake_loss=0.714, g_loss=0.694\n",
      "finish discriminator training\n",
      "Epoch:1, batch:76/236, real_loss=0.848, fake_loss=0.725, g_loss=0.805\n",
      "finish discriminator training\n",
      "Epoch:1, batch:77/236, real_loss=0.716, fake_loss=0.650, g_loss=0.752\n",
      "finish discriminator training\n",
      "Epoch:1, batch:78/236, real_loss=0.658, fake_loss=0.662, g_loss=0.764\n",
      "finish discriminator training\n",
      "Epoch:1, batch:79/236, real_loss=0.698, fake_loss=0.663, g_loss=0.778\n",
      "finish discriminator training\n",
      "Epoch:1, batch:80/236, real_loss=0.794, fake_loss=0.738, g_loss=0.766\n",
      "finish discriminator training\n",
      "Epoch:1, batch:81/236, real_loss=0.614, fake_loss=0.738, g_loss=0.792\n",
      "finish discriminator training\n",
      "Epoch:1, batch:82/236, real_loss=0.716, fake_loss=0.698, g_loss=0.815\n",
      "finish discriminator training\n",
      "Epoch:1, batch:83/236, real_loss=0.814, fake_loss=0.909, g_loss=0.838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish discriminator training\n",
      "Epoch:1, batch:84/236, real_loss=0.834, fake_loss=1.059, g_loss=0.802\n",
      "finish discriminator training\n",
      "Epoch:1, batch:85/236, real_loss=0.661, fake_loss=0.680, g_loss=0.775\n",
      "finish discriminator training\n",
      "Epoch:1, batch:86/236, real_loss=0.532, fake_loss=0.782, g_loss=0.771\n",
      "finish discriminator training\n",
      "Epoch:1, batch:87/236, real_loss=0.808, fake_loss=0.680, g_loss=0.780\n",
      "finish discriminator training\n",
      "Epoch:1, batch:88/236, real_loss=0.534, fake_loss=0.643, g_loss=0.757\n",
      "finish discriminator training\n",
      "Epoch:1, batch:89/236, real_loss=0.797, fake_loss=0.828, g_loss=0.777\n",
      "finish discriminator training\n",
      "Epoch:1, batch:90/236, real_loss=0.768, fake_loss=0.763, g_loss=0.756\n",
      "finish discriminator training\n",
      "Epoch:1, batch:91/236, real_loss=0.602, fake_loss=0.651, g_loss=0.798\n",
      "finish discriminator training\n",
      "Epoch:1, batch:92/236, real_loss=0.767, fake_loss=0.726, g_loss=0.782\n",
      "finish discriminator training\n",
      "Epoch:1, batch:93/236, real_loss=0.675, fake_loss=0.882, g_loss=0.777\n",
      "finish discriminator training\n",
      "Epoch:1, batch:94/236, real_loss=0.660, fake_loss=0.571, g_loss=0.765\n",
      "finish discriminator training\n",
      "Epoch:1, batch:95/236, real_loss=0.682, fake_loss=0.999, g_loss=0.757\n",
      "finish discriminator training\n",
      "Epoch:1, batch:96/236, real_loss=0.709, fake_loss=0.681, g_loss=0.775\n",
      "finish discriminator training\n",
      "Epoch:1, batch:97/236, real_loss=0.574, fake_loss=0.872, g_loss=0.727\n",
      "finish discriminator training\n",
      "Epoch:1, batch:98/236, real_loss=0.786, fake_loss=0.742, g_loss=0.792\n",
      "finish discriminator training\n",
      "Epoch:1, batch:99/236, real_loss=0.733, fake_loss=0.786, g_loss=0.824\n",
      "finish discriminator training\n",
      "Epoch:1, batch:100/236, real_loss=0.664, fake_loss=0.954, g_loss=0.754\n",
      "finish discriminator training\n",
      "Epoch:1, batch:101/236, real_loss=0.688, fake_loss=0.709, g_loss=0.836\n",
      "finish discriminator training\n",
      "Epoch:1, batch:102/236, real_loss=0.550, fake_loss=0.646, g_loss=0.792\n",
      "finish discriminator training\n",
      "Epoch:1, batch:103/236, real_loss=0.470, fake_loss=0.742, g_loss=0.778\n",
      "finish discriminator training\n",
      "Epoch:1, batch:104/236, real_loss=0.790, fake_loss=0.769, g_loss=0.793\n",
      "finish discriminator training\n",
      "Epoch:1, batch:105/236, real_loss=0.709, fake_loss=0.801, g_loss=0.763\n",
      "finish discriminator training\n",
      "Epoch:1, batch:106/236, real_loss=0.525, fake_loss=0.721, g_loss=0.779\n",
      "finish discriminator training\n",
      "Epoch:1, batch:107/236, real_loss=0.673, fake_loss=0.851, g_loss=0.811\n",
      "finish discriminator training\n",
      "Epoch:1, batch:108/236, real_loss=0.610, fake_loss=0.942, g_loss=0.729\n",
      "finish discriminator training\n",
      "Epoch:1, batch:109/236, real_loss=0.658, fake_loss=0.806, g_loss=0.780\n",
      "finish discriminator training\n",
      "Epoch:1, batch:110/236, real_loss=0.511, fake_loss=0.879, g_loss=0.774\n",
      "finish discriminator training\n",
      "Epoch:1, batch:111/236, real_loss=0.626, fake_loss=0.722, g_loss=0.725\n",
      "finish discriminator training\n",
      "Epoch:1, batch:112/236, real_loss=0.602, fake_loss=0.694, g_loss=0.764\n",
      "finish discriminator training\n",
      "Epoch:1, batch:113/236, real_loss=0.784, fake_loss=0.638, g_loss=0.779\n",
      "finish discriminator training\n",
      "Epoch:1, batch:114/236, real_loss=0.739, fake_loss=0.791, g_loss=0.740\n",
      "finish discriminator training\n",
      "Epoch:1, batch:115/236, real_loss=0.716, fake_loss=0.760, g_loss=0.716\n",
      "finish discriminator training\n",
      "Epoch:1, batch:116/236, real_loss=0.755, fake_loss=0.692, g_loss=0.738\n",
      "finish discriminator training\n",
      "Epoch:1, batch:117/236, real_loss=0.689, fake_loss=0.747, g_loss=0.715\n",
      "finish discriminator training\n",
      "Epoch:1, batch:118/236, real_loss=0.653, fake_loss=0.686, g_loss=0.750\n",
      "finish discriminator training\n",
      "Epoch:1, batch:119/236, real_loss=0.667, fake_loss=0.750, g_loss=0.698\n",
      "finish discriminator training\n",
      "Epoch:1, batch:120/236, real_loss=0.719, fake_loss=0.668, g_loss=0.747\n",
      "finish discriminator training\n",
      "Epoch:1, batch:121/236, real_loss=0.853, fake_loss=0.672, g_loss=0.708\n",
      "finish discriminator training\n",
      "Epoch:1, batch:122/236, real_loss=0.625, fake_loss=0.725, g_loss=0.733\n",
      "finish discriminator training\n",
      "Epoch:1, batch:123/236, real_loss=0.696, fake_loss=0.842, g_loss=0.705\n",
      "finish discriminator training\n",
      "Epoch:1, batch:124/236, real_loss=0.604, fake_loss=0.690, g_loss=0.703\n",
      "finish discriminator training\n",
      "Epoch:1, batch:125/236, real_loss=0.578, fake_loss=0.712, g_loss=0.701\n",
      "finish discriminator training\n",
      "Epoch:1, batch:126/236, real_loss=0.843, fake_loss=0.737, g_loss=0.695\n",
      "finish discriminator training\n",
      "Epoch:1, batch:127/236, real_loss=0.655, fake_loss=0.646, g_loss=0.709\n",
      "finish discriminator training\n",
      "Epoch:1, batch:128/236, real_loss=0.737, fake_loss=0.673, g_loss=0.744\n",
      "finish discriminator training\n",
      "Epoch:1, batch:129/236, real_loss=0.732, fake_loss=0.693, g_loss=0.731\n",
      "finish discriminator training\n",
      "Epoch:1, batch:130/236, real_loss=0.705, fake_loss=0.655, g_loss=0.697\n",
      "finish discriminator training\n",
      "Epoch:1, batch:131/236, real_loss=0.751, fake_loss=0.549, g_loss=0.709\n",
      "finish discriminator training\n",
      "Epoch:1, batch:132/236, real_loss=0.695, fake_loss=0.639, g_loss=0.732\n",
      "finish discriminator training\n",
      "Epoch:1, batch:133/236, real_loss=0.773, fake_loss=0.704, g_loss=0.740\n",
      "finish discriminator training\n",
      "Epoch:1, batch:134/236, real_loss=0.646, fake_loss=0.733, g_loss=0.723\n",
      "finish discriminator training\n",
      "Epoch:1, batch:135/236, real_loss=0.561, fake_loss=0.873, g_loss=0.715\n",
      "finish discriminator training\n",
      "Epoch:1, batch:136/236, real_loss=0.675, fake_loss=0.646, g_loss=0.735\n",
      "finish discriminator training\n",
      "Epoch:1, batch:137/236, real_loss=0.704, fake_loss=0.702, g_loss=0.735\n",
      "finish discriminator training\n",
      "Epoch:1, batch:138/236, real_loss=0.719, fake_loss=0.768, g_loss=0.747\n",
      "finish discriminator training\n",
      "Epoch:1, batch:139/236, real_loss=0.795, fake_loss=0.716, g_loss=0.724\n",
      "finish discriminator training\n",
      "Epoch:1, batch:140/236, real_loss=0.688, fake_loss=0.837, g_loss=0.729\n",
      "finish discriminator training\n",
      "Epoch:1, batch:141/236, real_loss=0.601, fake_loss=0.849, g_loss=0.730\n",
      "finish discriminator training\n",
      "Epoch:1, batch:142/236, real_loss=0.694, fake_loss=0.771, g_loss=0.752\n",
      "finish discriminator training\n",
      "Epoch:1, batch:143/236, real_loss=0.704, fake_loss=0.770, g_loss=0.744\n",
      "finish discriminator training\n",
      "Epoch:1, batch:144/236, real_loss=0.790, fake_loss=0.791, g_loss=0.735\n",
      "finish discriminator training\n",
      "Epoch:1, batch:145/236, real_loss=0.553, fake_loss=0.802, g_loss=0.746\n",
      "finish discriminator training\n",
      "Epoch:1, batch:146/236, real_loss=0.733, fake_loss=0.671, g_loss=0.766\n",
      "finish discriminator training\n",
      "Epoch:1, batch:147/236, real_loss=0.602, fake_loss=0.763, g_loss=0.759\n",
      "finish discriminator training\n",
      "Epoch:1, batch:148/236, real_loss=0.594, fake_loss=0.721, g_loss=0.724\n",
      "finish discriminator training\n",
      "Epoch:1, batch:149/236, real_loss=0.718, fake_loss=0.727, g_loss=0.734\n",
      "finish discriminator training\n",
      "Epoch:1, batch:150/236, real_loss=0.712, fake_loss=0.709, g_loss=0.713\n",
      "finish discriminator training\n",
      "Epoch:1, batch:151/236, real_loss=0.632, fake_loss=0.596, g_loss=0.723\n",
      "finish discriminator training\n",
      "Epoch:1, batch:152/236, real_loss=0.685, fake_loss=0.730, g_loss=0.727\n",
      "finish discriminator training\n",
      "Epoch:1, batch:153/236, real_loss=0.664, fake_loss=0.729, g_loss=0.757\n",
      "finish discriminator training\n",
      "Epoch:1, batch:154/236, real_loss=0.683, fake_loss=0.720, g_loss=0.728\n",
      "finish discriminator training\n",
      "Epoch:1, batch:155/236, real_loss=0.594, fake_loss=0.734, g_loss=0.730\n",
      "finish discriminator training\n",
      "Epoch:1, batch:156/236, real_loss=0.773, fake_loss=0.787, g_loss=0.717\n",
      "finish discriminator training\n",
      "Epoch:1, batch:157/236, real_loss=0.646, fake_loss=0.690, g_loss=0.747\n",
      "finish discriminator training\n",
      "Epoch:1, batch:158/236, real_loss=0.682, fake_loss=0.738, g_loss=0.741\n",
      "finish discriminator training\n",
      "Epoch:1, batch:159/236, real_loss=0.625, fake_loss=0.788, g_loss=0.723\n",
      "finish discriminator training\n",
      "Epoch:1, batch:160/236, real_loss=0.680, fake_loss=0.779, g_loss=0.735\n",
      "finish discriminator training\n",
      "Epoch:1, batch:161/236, real_loss=0.645, fake_loss=0.760, g_loss=0.741\n",
      "finish discriminator training\n",
      "Epoch:1, batch:162/236, real_loss=0.666, fake_loss=0.701, g_loss=0.708\n",
      "finish discriminator training\n",
      "Epoch:1, batch:163/236, real_loss=0.618, fake_loss=0.717, g_loss=0.722\n",
      "finish discriminator training\n",
      "Epoch:1, batch:164/236, real_loss=0.695, fake_loss=0.617, g_loss=0.698\n",
      "finish discriminator training\n",
      "Epoch:1, batch:165/236, real_loss=0.614, fake_loss=0.669, g_loss=0.715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish discriminator training\n",
      "Epoch:1, batch:166/236, real_loss=0.678, fake_loss=0.682, g_loss=0.714\n",
      "finish discriminator training\n",
      "Epoch:1, batch:167/236, real_loss=0.641, fake_loss=0.633, g_loss=0.701\n",
      "finish discriminator training\n",
      "Epoch:1, batch:168/236, real_loss=0.681, fake_loss=0.629, g_loss=0.714\n",
      "finish discriminator training\n",
      "Epoch:1, batch:169/236, real_loss=0.711, fake_loss=0.740, g_loss=0.703\n",
      "finish discriminator training\n",
      "Epoch:1, batch:170/236, real_loss=0.701, fake_loss=0.723, g_loss=0.685\n",
      "finish discriminator training\n",
      "Epoch:1, batch:171/236, real_loss=0.702, fake_loss=0.670, g_loss=0.717\n",
      "finish discriminator training\n",
      "Epoch:1, batch:172/236, real_loss=0.663, fake_loss=0.657, g_loss=0.673\n",
      "finish discriminator training\n",
      "Epoch:1, batch:173/236, real_loss=0.685, fake_loss=0.793, g_loss=0.682\n",
      "finish discriminator training\n",
      "Epoch:1, batch:174/236, real_loss=0.648, fake_loss=0.610, g_loss=0.684\n",
      "finish discriminator training\n",
      "Epoch:1, batch:175/236, real_loss=0.619, fake_loss=0.716, g_loss=0.712\n",
      "finish discriminator training\n",
      "Epoch:1, batch:176/236, real_loss=0.748, fake_loss=0.676, g_loss=0.695\n",
      "finish discriminator training\n",
      "Epoch:1, batch:177/236, real_loss=0.688, fake_loss=0.689, g_loss=0.722\n",
      "finish discriminator training\n",
      "Epoch:1, batch:178/236, real_loss=0.665, fake_loss=0.692, g_loss=0.686\n",
      "finish discriminator training\n",
      "Epoch:1, batch:179/236, real_loss=0.700, fake_loss=0.685, g_loss=0.733\n",
      "finish discriminator training\n",
      "Epoch:1, batch:180/236, real_loss=0.713, fake_loss=0.711, g_loss=0.693\n",
      "finish discriminator training\n",
      "Epoch:1, batch:181/236, real_loss=0.676, fake_loss=0.787, g_loss=0.718\n",
      "finish discriminator training\n",
      "Epoch:1, batch:182/236, real_loss=0.662, fake_loss=0.640, g_loss=0.706\n",
      "finish discriminator training\n",
      "Epoch:1, batch:183/236, real_loss=0.669, fake_loss=0.662, g_loss=0.715\n",
      "finish discriminator training\n",
      "Epoch:1, batch:184/236, real_loss=0.721, fake_loss=0.644, g_loss=0.683\n",
      "finish discriminator training\n",
      "Epoch:1, batch:185/236, real_loss=0.717, fake_loss=0.765, g_loss=0.730\n",
      "finish discriminator training\n",
      "Epoch:1, batch:186/236, real_loss=0.677, fake_loss=0.670, g_loss=0.717\n",
      "finish discriminator training\n",
      "Epoch:1, batch:187/236, real_loss=0.646, fake_loss=0.765, g_loss=0.722\n",
      "finish discriminator training\n",
      "Epoch:1, batch:188/236, real_loss=0.643, fake_loss=0.605, g_loss=0.721\n",
      "finish discriminator training\n",
      "Epoch:1, batch:189/236, real_loss=0.639, fake_loss=0.709, g_loss=0.726\n",
      "finish discriminator training\n",
      "Epoch:1, batch:190/236, real_loss=0.704, fake_loss=0.808, g_loss=0.733\n",
      "finish discriminator training\n",
      "Epoch:1, batch:191/236, real_loss=0.700, fake_loss=0.705, g_loss=0.708\n",
      "finish discriminator training\n",
      "Epoch:1, batch:192/236, real_loss=0.665, fake_loss=0.730, g_loss=0.727\n",
      "finish discriminator training\n",
      "Epoch:1, batch:193/236, real_loss=0.665, fake_loss=0.728, g_loss=0.721\n",
      "finish discriminator training\n",
      "Epoch:1, batch:194/236, real_loss=0.633, fake_loss=0.648, g_loss=0.724\n",
      "finish discriminator training\n",
      "Epoch:1, batch:195/236, real_loss=0.711, fake_loss=0.760, g_loss=0.701\n",
      "finish discriminator training\n",
      "Epoch:1, batch:196/236, real_loss=0.605, fake_loss=0.756, g_loss=0.719\n",
      "finish discriminator training\n",
      "Epoch:1, batch:197/236, real_loss=0.630, fake_loss=0.597, g_loss=0.735\n",
      "finish discriminator training\n",
      "Epoch:1, batch:198/236, real_loss=0.601, fake_loss=0.722, g_loss=0.726\n",
      "finish discriminator training\n",
      "Epoch:1, batch:199/236, real_loss=0.571, fake_loss=0.677, g_loss=0.715\n",
      "finish discriminator training\n",
      "Epoch:1, batch:200/236, real_loss=0.696, fake_loss=0.681, g_loss=0.743\n",
      "finish discriminator training\n",
      "Epoch:1, batch:201/236, real_loss=0.683, fake_loss=0.754, g_loss=0.727\n",
      "finish discriminator training\n",
      "Epoch:1, batch:202/236, real_loss=0.573, fake_loss=0.672, g_loss=0.752\n",
      "finish discriminator training\n",
      "Epoch:1, batch:203/236, real_loss=0.830, fake_loss=0.858, g_loss=0.766\n",
      "finish discriminator training\n",
      "Epoch:1, batch:204/236, real_loss=0.589, fake_loss=0.871, g_loss=0.739\n",
      "finish discriminator training\n",
      "Epoch:1, batch:205/236, real_loss=0.694, fake_loss=0.687, g_loss=0.765\n",
      "finish discriminator training\n",
      "Epoch:1, batch:206/236, real_loss=0.590, fake_loss=0.816, g_loss=0.713\n",
      "finish discriminator training\n",
      "Epoch:1, batch:207/236, real_loss=0.585, fake_loss=0.675, g_loss=0.758\n",
      "finish discriminator training\n",
      "Epoch:1, batch:208/236, real_loss=0.553, fake_loss=0.712, g_loss=0.757\n",
      "finish discriminator training\n",
      "Epoch:1, batch:209/236, real_loss=0.618, fake_loss=0.827, g_loss=0.778\n",
      "finish discriminator training\n",
      "Epoch:1, batch:210/236, real_loss=0.683, fake_loss=0.666, g_loss=0.747\n",
      "finish discriminator training\n",
      "Epoch:1, batch:211/236, real_loss=0.613, fake_loss=0.657, g_loss=0.748\n",
      "finish discriminator training\n",
      "Epoch:1, batch:212/236, real_loss=0.728, fake_loss=0.798, g_loss=0.727\n",
      "finish discriminator training\n",
      "Epoch:1, batch:213/236, real_loss=0.692, fake_loss=0.657, g_loss=0.747\n",
      "finish discriminator training\n",
      "Epoch:1, batch:214/236, real_loss=0.659, fake_loss=0.713, g_loss=0.716\n",
      "finish discriminator training\n",
      "Epoch:1, batch:215/236, real_loss=0.794, fake_loss=0.812, g_loss=0.712\n",
      "finish discriminator training\n",
      "Epoch:1, batch:216/236, real_loss=0.688, fake_loss=0.684, g_loss=0.710\n",
      "finish discriminator training\n",
      "Epoch:1, batch:217/236, real_loss=0.647, fake_loss=0.734, g_loss=0.738\n",
      "finish discriminator training\n",
      "Epoch:1, batch:218/236, real_loss=0.757, fake_loss=0.651, g_loss=0.714\n",
      "finish discriminator training\n",
      "Epoch:1, batch:219/236, real_loss=0.759, fake_loss=0.558, g_loss=0.700\n",
      "finish discriminator training\n",
      "Epoch:1, batch:220/236, real_loss=0.665, fake_loss=0.675, g_loss=0.707\n",
      "finish discriminator training\n",
      "Epoch:1, batch:221/236, real_loss=0.655, fake_loss=0.661, g_loss=0.714\n",
      "finish discriminator training\n",
      "Epoch:1, batch:222/236, real_loss=0.768, fake_loss=0.721, g_loss=0.688\n",
      "finish discriminator training\n",
      "Epoch:1, batch:223/236, real_loss=0.755, fake_loss=0.706, g_loss=0.719\n",
      "finish discriminator training\n",
      "Epoch:1, batch:224/236, real_loss=0.668, fake_loss=0.644, g_loss=0.692\n",
      "finish discriminator training\n",
      "Epoch:1, batch:225/236, real_loss=0.613, fake_loss=0.802, g_loss=0.723\n",
      "finish discriminator training\n",
      "Epoch:1, batch:226/236, real_loss=0.647, fake_loss=0.690, g_loss=0.692\n",
      "finish discriminator training\n",
      "Epoch:1, batch:227/236, real_loss=0.642, fake_loss=0.769, g_loss=0.716\n",
      "finish discriminator training\n",
      "Epoch:1, batch:228/236, real_loss=0.681, fake_loss=0.693, g_loss=0.689\n",
      "finish discriminator training\n",
      "Epoch:1, batch:229/236, real_loss=0.687, fake_loss=0.704, g_loss=0.694\n",
      "finish discriminator training\n",
      "Epoch:1, batch:230/236, real_loss=0.723, fake_loss=0.627, g_loss=0.702\n",
      "finish discriminator training\n",
      "Epoch:1, batch:231/236, real_loss=0.769, fake_loss=0.671, g_loss=0.678\n",
      "finish discriminator training\n",
      "Epoch:1, batch:232/236, real_loss=0.681, fake_loss=0.763, g_loss=0.702\n",
      "finish discriminator training\n",
      "Epoch:1, batch:233/236, real_loss=0.696, fake_loss=0.655, g_loss=0.697\n",
      "finish discriminator training\n",
      "Epoch:1, batch:234/236, real_loss=0.704, fake_loss=0.737, g_loss=0.685\n",
      "finish discriminator training\n",
      "Epoch:1, batch:235/236, real_loss=0.678, fake_loss=0.707, g_loss=0.706\n",
      "finish discriminator training\n",
      "Epoch:1, batch:236/236, real_loss=0.717, fake_loss=0.629, g_loss=0.722\n"
     ]
    }
   ],
   "source": [
    "cGAN = Condition_GAN(generator, discriminator, lr=0.000001)\n",
    "cGAN.fit(1, 100, [X_high, X_low, X_ele, X_other], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.91267836, 0.91228503, 0.91213405, 0.9122523 , 0.9117179 ],\n",
       "         [0.9126853 , 0.9119334 , 0.9123945 , 0.91228676, 0.912086  ],\n",
       "         [0.91253626, 0.91179043, 0.9122256 , 0.9113081 , 0.9117612 ],\n",
       "         [0.9126473 , 0.9124548 , 0.9114045 , 0.91186583, 0.91165435],\n",
       "         [0.91253436, 0.9130199 , 0.9113524 , 0.9112941 , 0.91221786]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.predict([X_high[-1:], X_low[-1:], X_ele[-1:], X_other[-1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [X_high, X_low, X_ele, X_other]\n",
    "j =0\n",
    "batch_size=2\n",
    "batch_X = [d[j*batch_size:(j+1)*batch_size] for d in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 5, 5, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((batch_size, 1), dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. downscaler test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(downscale)\n",
    "from util_tools import downscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscler = downscale.downscaler(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_data = g_data[10:10+n_lag]\n",
    "l_data = m_data[1836: 1856]\n",
    "days = list(range(1836, 1856))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscaled_data = dscler.downscale(h_data, l_data, ele_data,  [G_lats, G_lons, M_lats, M_lons], days, n_lag, n_pred, task_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 123, 207)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downscaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 123, 207)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.934871974800356"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downscaled_data[4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9450469764791418"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_data[10+4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Downscale_env",
   "language": "python",
   "name": "downscale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
